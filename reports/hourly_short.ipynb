{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:43.907407600Z",
     "start_time": "2024-02-03T08:27:40.797000200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta  # For working with dates\n",
    "\n",
    "import pandas as pd  # For working with DataFrames\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import NamedStyle, PatternFill, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from sqlalchemy import create_engine  # For crea\n",
    "\n",
    "##################### LOADING IMPORTANT DATA ######################\n",
    "# Load environment variables from the .env file\n",
    "env_file_path = 'D:/Projects/.env'\n",
    "load_dotenv(env_file_path)\n",
    "# Giving output file name\n",
    "output_file_path = 'HOURLY.xlsx'\n",
    "# Load data from different sheets in 'promotion.xlsx' into DataFrames\n",
    "promotion_path = 'D:\\Projects\\promotion.xlsx'\n",
    "region_df = pd.read_excel(promotion_path, sheet_name='Region')\n",
    "aksiya_df = pd.read_excel(promotion_path, sheet_name='Aksiya')\n",
    "paket_df = pd.read_excel(promotion_path, sheet_name='Paket')\n",
    "types_df = pd.read_excel(promotion_path, sheet_name='TYPES')\n",
    "\n",
    "##################### ACCESS ENV VARIABLES ######################\n",
    "db_server = os.getenv(\"DB_SERVER\")\n",
    "db_database = os.getenv(\"DB_DATABASE_SERGELI\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_driver_name = os.getenv(\"DB_DRIVER_NAME\")\n",
    "\n",
    "##################### PROCEDURE NAME ######################\n",
    "procedure_name = os.getenv(\"HOURLY_SHORT\")  # THIS IS HOURLY DATA GATHERING\n",
    "\n",
    "##################### DATE - JANUARY ######################\n",
    "CURRENT_MONTH = 1\n",
    "CURRENT_YEAR = 2024\n",
    "today_date = datetime.now().strftime('%d/%m/%Y')\n",
    "tomorrow_date = (datetime.now() + timedelta(days=1)).strftime('%d/%m/%Y')\n",
    "##################### CONNECTION STRING AND SQL QUERY ######################\n",
    "# Construct the connection string\n",
    "conn_str = f\"mssql+pyodbc://{db_user}:{db_password}@{db_server}:{db_port}/{db_database}?driver={db_driver_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "sql_query = f\"\"\"\n",
    "    DECLARE @DateBegin DATE = ?;\n",
    "    DECLARE @DateEnd DATE = ?;\n",
    "\n",
    "    EXEC {procedure_name}\n",
    "        @DateBegin = @DateBegin,\n",
    "        @DateEnd = @DateBegin;\n",
    "\"\"\"\n",
    "\n",
    "#####################  EXECUTION  ######################\n",
    "df = pd.read_sql_query(sql_query, engine, params=(today_date, tomorrow_date))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'DocumentType', 'Invoice Number', 'Goodid', 'Good', 'Manufacturer',\n",
    "    'inn', 'ClientName', 'SalesManager', 'ClientMan', 'PaymentTerm',\n",
    "    'BasePrice', 'SellingPrice', 'Quantity', 'DateEntered', 'BaseAmount', 'TotalAmount'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:45.630471700Z",
     "start_time": "2024-02-03T08:27:45.619206800Z"
    }
   },
   "id": "c887a8874533cd9b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "##################### BASIC FILTER ######################\n",
    "df = df[df['DocumentType'].isin(['Оптовая реализация', 'Финансовая скидка'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:47.285565300Z",
     "start_time": "2024-02-03T08:27:47.264996500Z"
    }
   },
   "id": "852e1e87b74007c3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(df, region_df[['ClientMan', 'Region']], left_on='ClientMan', right_on='ClientMan', how='left')\n",
    "\n",
    "df = pd.merge(df, aksiya_df[['Goodid', 'Aksiya']], left_on='Goodid', right_on='Goodid', how='left')\n",
    "df = pd.merge(df, paket_df[['Goodid', 'Paket']], left_on='Goodid', right_on='Goodid', how='left')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:48.345935700Z",
     "start_time": "2024-02-03T08:27:48.323402600Z"
    }
   },
   "id": "f387e0214985f7ec",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['inn_temp'] = pd.to_numeric(df['inn'], errors='coerce')\n",
    "types_df['INN_temp'] = pd.to_numeric(types_df['INN'], errors='coerce')\n",
    "df = pd.merge(df, types_df[['INN_temp', 'TYPE', 'RegionType']], left_on='inn_temp', right_on='INN_temp', how='left')\n",
    "df['TYPE'].fillna('ROZ', inplace=True)\n",
    "df.loc[df['TYPE'] == 'ROZ', 'RegionType'] = df['Region']\n",
    "\n",
    "df['OXVAT'] = df['inn'].map(df['inn'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:49.491748900Z",
     "start_time": "2024-02-03T08:27:49.465416100Z"
    }
   },
   "id": "9b7bbd643dbeffce",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categorical_columns = ['DocumentType', 'Good', 'Manufacturer', 'inn', 'ClientName', 'SalesManager', 'ClientMan',\n",
    "                       'PaymentTerm', 'Region', 'RegionType', 'TYPE']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:50.083798200Z",
     "start_time": "2024-02-03T08:27:50.079309300Z"
    }
   },
   "id": "2869ce3355f6cf39",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[categorical_columns] = df[categorical_columns].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:51.301335500Z",
     "start_time": "2024-02-03T08:27:51.281079700Z"
    }
   },
   "id": "287803cdabb6efa0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "columns_to_drop = [col for col in df.columns if col.endswith('_temp')]\n",
    "\n",
    "# Drop the identified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.to_excel(output_file_path,index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:52.026046700Z",
     "start_time": "2024-02-03T08:27:51.876453900Z"
    }
   },
   "id": "8ff8c172551f1af0",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FORMATTING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb59aa452f9399b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the existing workbook\n",
    "workbook = load_workbook(output_file_path)\n",
    "\n",
    "# Access the default sheet (assuming it's the only sheet in the workbook)\n",
    "worksheet = workbook.active\n",
    "\n",
    "# 1. Color first row (headers) with 4CB9E7 color code\n",
    "header_style = NamedStyle(name='header_style', fill=PatternFill(\n",
    "    start_color='4CB9E7', end_color='4CB9E7', fill_type='solid'))\n",
    "\n",
    "for cell in worksheet[1]:\n",
    "    cell.style = header_style\n",
    "\n",
    "# 2. Autofit all columns\n",
    "for column in worksheet.columns:\n",
    "    max_length = 0\n",
    "    column = [cell for cell in column]\n",
    "    for cell in column:\n",
    "        try:\n",
    "            value = str(cell.value)\n",
    "            if len(value) > max_length:\n",
    "                max_length = len(value)\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 5)\n",
    "    column_letter = get_column_letter(column[0].column)\n",
    "    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# 3. Format columns with thousands separators\n",
    "number_format = NamedStyle(\n",
    "    name='number_format', number_format='### ### ### ##0')\n",
    "\n",
    "# Specify the columns to format based on float64 datatype\n",
    "# Specify the columns to format based on float64 datatype\n",
    "float64_columns = df.select_dtypes(include=['float64']).columns\n",
    "for col in float64_columns:\n",
    "    col_index = df.columns.get_loc(col) + 1  # 1-based index\n",
    "    col_letter = get_column_letter(col_index)\n",
    "\n",
    "    for cell in worksheet[col_letter][1:]:  # Start from the second row assuming the first row is headers\n",
    "        try:\n",
    "            formatted_value = \"{:,.2f}\".format(float(cell.value))\n",
    "            cell.value = float(cell.value)\n",
    "            cell.style = number_format\n",
    "        except (ValueError, TypeError):\n",
    "            # Handle cases where the cell value is not a valid number\n",
    "            pass\n",
    "\n",
    "# # Get the last column letter\n",
    "# last_column_letter = get_column_letter(worksheet.max_column)\n",
    "# \n",
    "# # Apply background color to all cells in the last column\n",
    "# for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=worksheet.max_column,\n",
    "#                                max_col=worksheet.max_column):\n",
    "#     for cell in row:\n",
    "#         cell.fill = PatternFill(start_color='A0D8B3', end_color='A0D8B3', fill_type='solid')\n",
    "\n",
    "# Add borders to all cells with data\n",
    "for row in worksheet.iter_rows(min_row=1, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "    for cell in row:\n",
    "        cell.border = Border(\n",
    "            left=Side(style='thin'),\n",
    "            right=Side(style='thin'),\n",
    "            top=Side(style='thin'),\n",
    "            bottom=Side(style='thin')\n",
    "        )\n",
    "\n",
    "workbook.save(output_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:27:54.986106900Z",
     "start_time": "2024-02-03T08:27:54.473163900Z"
    }
   },
   "id": "34eda21c06e73952",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TO'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 64\u001B[0m\n\u001B[0;32m     61\u001B[0m unique_types \u001B[38;5;241m=\u001B[39m filtered_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTYPE\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39munique()\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Defined the specific Plan Columns i need\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m region_combinations \u001B[38;5;241m=\u001B[39m \u001B[43mplan_df\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRegion\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTO\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRinomaks\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mForsil\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mТризим Таб\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mТризим Кап\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mЭнтеросгель\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;66;03m# Calculate 'Факт ТО' and '%' for each product type\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m product_type \u001B[38;5;129;01min\u001B[39;00m unique_types:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3899\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3897\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3898\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3899\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3901\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3902\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6112\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6113\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6115\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6117\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6119\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6178\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6179\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['TO'] not in index\""
     ]
    }
   ],
   "source": [
    "def calculate_oxvat(filtered_d, region):\n",
    "    \"\"\"\n",
    "    Calculate the count of unique clients based on the provided conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_df (DataFrame): A DataFrame filtered to include only rows where 'TYPE' is 'ROZ'.\n",
    "    - region (str): The specific region for which to calculate the count of unique clients.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of unique clients for the given region.\n",
    "    \"\"\"\n",
    "    return len(filtered_d[(filtered_d['RegionType'] == region) & (filtered_d['TYPE'] == 'ROZ')]['inn'].unique())\n",
    "\n",
    "\n",
    "def calculate_fact_to(region, region_type, *aksiya_value):\n",
    "    \"\"\"\n",
    "    Calculate the 'Факт ТО' for a specific region, product type, and aksiya value.\n",
    "\n",
    "    Parameters:\n",
    "    - region (str): The specific region for which to calculate 'Факт ТО'.\n",
    "    - region_type (str): The specific product type for which to calculate 'Факт ТО'.\n",
    "    - aksiya_value (str, optional): The specific value for 'aksiya' to be considered in the calculation.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated 'Факт ТО'.\n",
    "    \"\"\"\n",
    "    filtered_region_df = filtered_df[(filtered_df['Region'] == region) & (filtered_df['TYPE'] == region_type)]\n",
    "\n",
    "    if aksiya_value:\n",
    "        filtered_region_df = filtered_region_df[filtered_region_df['Aksiya'] == aksiya_value[0]]\n",
    "        return max(filtered_region_df['Kolich'].sum(), 0)\n",
    "\n",
    "    return max(filtered_region_df['TotalAmount'].sum(), 0)\n",
    "\n",
    "\n",
    "def calculate_percentage(fact_column, plan_column):\n",
    "    \"\"\"\n",
    "    Calculate the percentage based on 'Факт' and 'План' columns.\n",
    "\n",
    "    Parameters:\n",
    "    - fact_column (Series): The Series representing the 'Факт' column.\n",
    "    - plan_column (Series): The Series representing the 'План' column.\n",
    "\n",
    "    Returns:\n",
    "    Series: The calculated percentage column.\n",
    "    \"\"\"\n",
    "    return (fact_column / plan_column).fillna(1) * 100\n",
    "\n",
    "\n",
    "# Load data from hourly.xlsx\n",
    "input_file_path = 'Hourly.xlsx'\n",
    "plan_path = 'D:/Projects/plan.xlsx'\n",
    "# Read plan data from plan.xlsx\n",
    "plan_df = pd.read_excel(plan_path, sheet_name=\"ROZ\")\n",
    "df = pd.read_excel(input_file_path)\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'TYPE' is 'ROZ'\n",
    "filtered_df = df[df['TYPE'] == 'ROZ']\n",
    "\n",
    "# Define unique values for TYPE\n",
    "unique_types = filtered_df['TYPE'].unique()\n",
    "\n",
    "# Defined the specific Plan Columns i need\n",
    "region_combinations = plan_df[['Region', 'TO', 'Rinomaks', 'Forsil', 'Тризим Таб', 'Тризим Кап', 'Энтеросгель']]\n",
    "\n",
    "# Calculate 'Факт ТО' and '%' for each product type\n",
    "for product_type in unique_types:\n",
    "    fact_column = f'Fact ТО {product_type}'\n",
    "    percent_column = f'% {product_type}'\n",
    "\n",
    "    region_combinations[fact_column] = region_combinations['Region'].apply(\n",
    "        lambda region: calculate_fact_to(region, product_type))\n",
    "\n",
    "    region_combinations[percent_column] = calculate_percentage(region_combinations[fact_column],\n",
    "                                                               region_combinations['TO'])\n",
    "\n",
    "# Add 'OXVAT' column based on the provided formula\n",
    "region_combinations['OXVAT'] = region_combinations['Region'].apply(lambda region: calculate_oxvat(filtered_df, region))\n",
    "\n",
    "# Add Rinomaks columns\n",
    "region_combinations['Fact Rinomaks'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Рино'))\n",
    "region_combinations['% Rinomaks'] = calculate_percentage(region_combinations['Fact Rinomaks'],\n",
    "                                                         region_combinations['Rinomaks'])\n",
    "# FORSIL\n",
    "region_combinations['Fact FORSIL'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Форсил'))\n",
    "region_combinations['% FORSIL'] = calculate_percentage(region_combinations['Fact FORSIL'],\n",
    "                                                       region_combinations['Forsil'])\n",
    "\n",
    "region_combinations['Fact Тризим Таб'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Тризим №20'))\n",
    "region_combinations['% Тризим Таб'] = calculate_percentage(region_combinations['Fact Тризим Таб'],\n",
    "                                                           region_combinations['Тризим Таб'])\n",
    "\n",
    "region_combinations['Fact Тризим Кап'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Тризим Кап'))\n",
    "region_combinations['% Тризим Кап'] = calculate_percentage(region_combinations['Fact Тризим Кап'],\n",
    "                                                           region_combinations['Тризим Кап'])\n",
    "\n",
    "region_combinations['Fact Энтеросгель'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Энтеросгель'))\n",
    "region_combinations['% Энтеросгель'] = calculate_percentage(region_combinations['Fact Энтеросгель'],\n",
    "                                                            region_combinations['Энтеросгель'])\n",
    "# COLUMN RENAME TO RUSSIAN LETTERS FROM ENGLISH\n",
    "column_mapping = {\n",
    "    'Region': 'Регион',\n",
    "    'TO': 'TO',\n",
    "    'Fact ТО ROZ': 'Факт ТО',\n",
    "    '% ROZ': '% TO',\n",
    "    'OXVAT': 'Охват',\n",
    "    'Rinomaks': 'Риномакс',\n",
    "    'Fact Rinomaks': 'Факт Риномакс',\n",
    "    '% Rinomaks': '% Риномакс',\n",
    "    'Forsil': 'Форсил',\n",
    "    'Fact FORSIL': 'Факт Форсил',\n",
    "    '% FORSIL': '% Форсил',\n",
    "    'Тризим Таб': 'Тризим Таб',\n",
    "    'Fact Тризим Таб': 'Факт Тризим Таб',\n",
    "    '% Тризим Таб': '% Тризим Таб',\n",
    "    'Тризим Кап': 'Тризим Кап',\n",
    "    'Fact Тризим Кап': 'Факт Тризим Кап',\n",
    "    '% Тризим Кап': '% Тризим Кап',\n",
    "    'Энтеросгель': 'Энтеросгель',\n",
    "    'Fact Энтеросгель': 'Факт Энтеросгель',\n",
    "    '% Энтеросгель': '% Энтеросгель'\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping dictionary\n",
    "region_combinations = region_combinations.rename(columns=column_mapping)\n",
    "# Sorting to look it pretty\n",
    "region_combinations.sort_values(by='% TO', ascending=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:28:18.736048700Z",
     "start_time": "2024-02-03T08:28:18.583778Z"
    }
   },
   "id": "ae3218d782958698",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_row= pd.Series({\n",
    "    'Регион': 'TOTAL',\n",
    "    'TO': region_combinations['TO'].sum(),\n",
    "    'Факт ТО': region_combinations['Факт ТО'].sum(),\n",
    "    '% TO': (region_combinations['Факт ТО'].sum() / region_combinations['TO'].sum()) * 100,\n",
    "    'Охват': region_combinations['Охват'].sum(),\n",
    "    'Риномакс': region_combinations['Риномакс'].sum(),\n",
    "    'Факт Риномакс': region_combinations['Факт Риномакс'].sum(),\n",
    "    '% Риномакс': (region_combinations['Факт Риномакс'].sum() / region_combinations['Риномакс'].sum()) * 100,\n",
    "    'Форсил': region_combinations['Форсил'].sum(),\n",
    "    'Факт Форсил': region_combinations['Факт Форсил'].sum(),\n",
    "    '% Форсил': (region_combinations['Факт Форсил'].sum() / region_combinations['Форсил'].sum()) * 100,\n",
    "    'Тризим Таб': region_combinations['Тризим Таб'].sum(),\n",
    "    'Факт Тризим Таб': region_combinations['Факт Тризим Таб'].sum(),\n",
    "    '% Тризим Таб': (region_combinations['Факт Тризим Таб'].sum() / region_combinations['Тризим Таб'].sum()) * 100,\n",
    "    'Тризим Кап': region_combinations['Тризим Кап'].sum(),\n",
    "    'Факт Тризим Кап': region_combinations['Факт Тризим Кап'].sum(),\n",
    "    '% Тризим Кап': (region_combinations['Факт Тризим Кап'].sum() / region_combinations['Тризим Кап'].sum()) * 100,\n",
    "    'Энтеросгель': region_combinations['Энтеросгель'].sum(),\n",
    "    'Факт Энтеросгель': region_combinations['Факт Энтеросгель'].sum(),\n",
    "    '% Энтеросгель': (region_combinations['Факт Энтеросгель'].sum() / region_combinations['Энтеросгель'].sum()) * 100\n",
    "}, name='TOTAL')\n",
    "\n",
    "region_combinations = pd.concat([region_combinations, total_row.to_frame().transpose()], ignore_index=True)\n",
    "region_combinations=region_combinations[['Регион', 'TO', 'Факт ТО', '% TO', 'Охват', 'Риномакс', 'Факт Риномакс',\n",
    "                     '% Риномакс', 'Форсил', 'Факт Форсил', '% Форсил', 'Тризим Таб', 'Факт Тризим Таб',\n",
    "                     '% Тризим Таб', 'Тризим Кап', 'Факт Тризим Кап', '% Тризим Кап',\n",
    "                     'Энтеросгель', 'Факт Энтеросгель', '% Энтеросгель']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-03T08:25:58.126179700Z",
     "start_time": "2024-02-03T08:25:58.125183200Z"
    }
   },
   "id": "5ce376fbaf4b8b70",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "region_combinations.to_excel('Salom.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-03T08:25:58.129162200Z"
    }
   },
   "id": "46da1f2da139e4e8",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
