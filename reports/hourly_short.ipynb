{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:33.944824700Z",
     "start_time": "2024-01-24T12:39:30.993657Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta  # For working with dates\n",
    "\n",
    "import pandas as pd  # For working with DataFrames\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import NamedStyle, PatternFill, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from sqlalchemy import create_engine  # For crea\n",
    "\n",
    "##################### LOADING IMPORTANT DATA ######################\n",
    "# Load environment variables from the .env file\n",
    "env_file_path = 'D:/Projects/.env'\n",
    "load_dotenv(env_file_path)\n",
    "# Giving output file name\n",
    "output_file_path = 'HOURLY.xlsx'\n",
    "# Load data from different sheets in 'promotion.xlsx' into DataFrames\n",
    "promotion_path = 'D:\\Projects\\promotion.xlsx'\n",
    "region_df = pd.read_excel(promotion_path, sheet_name='Region')\n",
    "aksiya_df = pd.read_excel(promotion_path, sheet_name='Aksiya')\n",
    "paket_df = pd.read_excel(promotion_path, sheet_name='Paket')\n",
    "types_df = pd.read_excel(promotion_path, sheet_name='TYPES')\n",
    "\n",
    "##################### ACCESS ENV VARIABLES ######################\n",
    "db_server = os.getenv(\"DB_SERVER\")\n",
    "db_database = os.getenv(\"DB_DATABASE_SERGELI\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_driver_name = os.getenv(\"DB_DRIVER_NAME\")\n",
    "\n",
    "##################### PROCEDURE NAME ######################\n",
    "procedure_name = 'zAdmReportDFS_short'  # THIS IS HOURLY DATA GATHERING\n",
    "\n",
    "##################### DATE - JANUARY ######################\n",
    "CURRENT_MONTH = 1\n",
    "CURRENT_YEAR = 2024\n",
    "today_date = datetime.now().strftime('%d/%m/%Y')\n",
    "tomorrow_date = (datetime.now() + timedelta(days=1)).strftime('%d/%m/%Y')\n",
    "##################### CONNECTION STRING AND SQL QUERY ######################\n",
    "# Construct the connection string\n",
    "conn_str = f\"mssql+pyodbc://{db_user}:{db_password}@{db_server}:{db_port}/{db_database}?driver={db_driver_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "sql_query = f\"\"\"\n",
    "    DECLARE @DateBegin DATE = ?;\n",
    "    DECLARE @DateEnd DATE = ?;\n",
    "\n",
    "    EXEC {procedure_name}\n",
    "        @DateBegin = @DateBegin,\n",
    "        @DateEnd = @DateBegin;\n",
    "\"\"\"\n",
    "\n",
    "#####################  EXECUTION  ######################\n",
    "df = pd.read_sql_query(sql_query, engine, params=(today_date, tomorrow_date))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'DocumentType', 'Invoice Number', 'Goodid', 'Good', 'Manufacturer',\n",
    "    'inn', 'ClientName', 'SalesManager', 'ClientMan', 'PaymentTerm',\n",
    "    'BasePrice', 'SellingPrice', 'Quantity', 'DateEntered', 'BaseAmount', 'TotalAmount'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:33.957003400Z",
     "start_time": "2024-01-24T12:39:33.947357100Z"
    }
   },
   "id": "c887a8874533cd9b",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "##################### BASIC FILTER ######################\n",
    "df = df[df['DocumentType'].isin(['Оптовая реализация', 'Финансовая скидка'])]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:33.969313800Z",
     "start_time": "2024-01-24T12:39:33.954977200Z"
    }
   },
   "id": "852e1e87b74007c3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "df = pd.merge(df, region_df[['ClientMan', 'Region']], left_on='ClientMan', right_on='ClientMan', how='left')\n",
    "\n",
    "df = pd.merge(df, aksiya_df[['Goodid', 'Aksiya']], left_on='Goodid', right_on='Goodid', how='left')\n",
    "df = pd.merge(df, paket_df[['Goodid', 'Paket']], left_on='Goodid', right_on='Goodid', how='left')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:33.991405400Z",
     "start_time": "2024-01-24T12:39:33.967932500Z"
    }
   },
   "id": "f387e0214985f7ec",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['inn_temp'] = pd.to_numeric(df['inn'], errors='coerce')\n",
    "types_df['INN_temp'] = pd.to_numeric(types_df['INN'], errors='coerce')\n",
    "df = pd.merge(df, types_df[['INN_temp', 'TYPE', 'RegionType']], left_on='inn_temp', right_on='INN_temp', how='left')\n",
    "df['TYPE'].fillna('ROZ', inplace=True)\n",
    "df.loc[df['TYPE'] == 'ROZ', 'RegionType'] = df['Region']\n",
    "\n",
    "df['OXVAT'] = df['inn'].map(df['inn'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:34.034853500Z",
     "start_time": "2024-01-24T12:39:33.994466Z"
    }
   },
   "id": "9b7bbd643dbeffce",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "categorical_columns = ['DocumentType', 'Good', 'Manufacturer', 'inn', 'ClientName', 'SalesManager', 'ClientMan',\n",
    "                       'PaymentTerm', 'Region', 'RegionType', 'TYPE']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:34.036878200Z",
     "start_time": "2024-01-24T12:39:34.025441900Z"
    }
   },
   "id": "2869ce3355f6cf39",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[categorical_columns] = df[categorical_columns].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:34.075939800Z",
     "start_time": "2024-01-24T12:39:34.034853500Z"
    }
   },
   "id": "287803cdabb6efa0",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:34.077013Z",
     "start_time": "2024-01-24T12:39:34.070474900Z"
    }
   },
   "id": "d47488510e23d209",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "columns_to_drop = [col for col in df.columns if col.endswith('_temp')]\n",
    "\n",
    "# Drop the identified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "df.to_excel(output_file_path,)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:35.408644800Z",
     "start_time": "2024-01-24T12:39:34.075939800Z"
    }
   },
   "id": "8ff8c172551f1af0",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FORMATTING"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb59aa452f9399b1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the existing workbook\n",
    "workbook = load_workbook(output_file_path)\n",
    "\n",
    "# Access the default sheet (assuming it's the only sheet in the workbook)\n",
    "worksheet = workbook.active\n",
    "\n",
    "# 1. Color first row (headers) with 4CB9E7 color code\n",
    "header_style = NamedStyle(name='header_style', fill=PatternFill(\n",
    "    start_color='4CB9E7', end_color='4CB9E7', fill_type='solid'))\n",
    "\n",
    "for cell in worksheet[1]:\n",
    "    cell.style = header_style\n",
    "\n",
    "# 2. Autofit all columns\n",
    "for column in worksheet.columns:\n",
    "    max_length = 0\n",
    "    column = [cell for cell in column]\n",
    "    for cell in column:\n",
    "        try:\n",
    "            value = str(cell.value)\n",
    "            if len(value) > max_length:\n",
    "                max_length = len(value)\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 5)\n",
    "    column_letter = get_column_letter(column[0].column)\n",
    "    worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "# 3. Format columns with thousands separators\n",
    "number_format = NamedStyle(\n",
    "    name='number_format', number_format='### ### ### ##0')\n",
    "\n",
    "# Specify the columns to format based on float64 datatype\n",
    "# Specify the columns to format based on float64 datatype\n",
    "float64_columns = df.select_dtypes(include=['float64']).columns\n",
    "for col in float64_columns:\n",
    "    col_index = df.columns.get_loc(col) + 1  # 1-based index\n",
    "    col_letter = get_column_letter(col_index)\n",
    "\n",
    "    for cell in worksheet[col_letter][1:]:  # Start from the second row assuming the first row is headers\n",
    "        try:\n",
    "            formatted_value = \"{:,.2f}\".format(float(cell.value))\n",
    "            cell.value = float(cell.value)\n",
    "            cell.style = number_format\n",
    "        except (ValueError, TypeError):\n",
    "            # Handle cases where the cell value is not a valid number\n",
    "            pass\n",
    "\n",
    "# # Get the last column letter\n",
    "# last_column_letter = get_column_letter(worksheet.max_column)\n",
    "# \n",
    "# # Apply background color to all cells in the last column\n",
    "# for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=worksheet.max_column,\n",
    "#                                max_col=worksheet.max_column):\n",
    "#     for cell in row:\n",
    "#         cell.fill = PatternFill(start_color='A0D8B3', end_color='A0D8B3', fill_type='solid')\n",
    "\n",
    "# Add borders to all cells with data\n",
    "for row in worksheet.iter_rows(min_row=1, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "    for cell in row:\n",
    "        cell.border = Border(\n",
    "            left=Side(style='thin'),\n",
    "            right=Side(style='thin'),\n",
    "            top=Side(style='thin'),\n",
    "            bottom=Side(style='thin')\n",
    "        )\n",
    "\n",
    "workbook.save(output_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:42.265134200Z",
     "start_time": "2024-01-24T12:39:35.419335500Z"
    }
   },
   "id": "34eda21c06e73952",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Kolich'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3790\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3791\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3792\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Kolich'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 81\u001B[0m\n\u001B[0;32m     78\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOXVAT\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRegion\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m region: calculate_oxvat(filtered_df, region))\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# Add Rinomaks columns\u001B[39;00m\n\u001B[1;32m---> 81\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFact Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mregion_combinations\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRegion\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mregion\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mcalculate_fact_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mregion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mROZ\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mРино\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m calculate_percentage(region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFact Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     84\u001B[0m                                                          region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# FORSIL\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4629\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4630\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4631\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4636\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4637\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4638\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4639\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4640\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4755\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4756\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4758\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4761\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4762\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4764\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1208\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1209\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1283\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1284\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1285\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1286\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1287\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1288\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1289\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1291\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1294\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1295\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1812\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1814\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1816\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1817\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1818\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2926\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[43], line 82\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(region)\u001B[0m\n\u001B[0;32m     78\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOXVAT\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRegion\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m region: calculate_oxvat(filtered_df, region))\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# Add Rinomaks columns\u001B[39;00m\n\u001B[0;32m     81\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFact Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRegion\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\n\u001B[1;32m---> 82\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m region: \u001B[43mcalculate_fact_to\u001B[49m\u001B[43m(\u001B[49m\u001B[43mregion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mROZ\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mРино\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     83\u001B[0m region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m calculate_percentage(region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFact Rinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     84\u001B[0m                                                          region_combinations[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRinomaks\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# FORSIL\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[43], line 31\u001B[0m, in \u001B[0;36mcalculate_fact_to\u001B[1;34m(region, region_type, *aksiya_value)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aksiya_value:\n\u001B[0;32m     30\u001B[0m     filtered_region_df \u001B[38;5;241m=\u001B[39m filtered_region_df[filtered_region_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAksiya\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m aksiya_value[\u001B[38;5;241m0\u001B[39m]]\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[43mfiltered_region_df\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mKolich\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39msum(), \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(filtered_region_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTotalAmount\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msum(), \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3893\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3895\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3793\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3794\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3795\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3796\u001B[0m     ):\n\u001B[0;32m   3797\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3799\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3801\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3803\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'Kolich'"
     ]
    }
   ],
   "source": [
    "def calculate_oxvat(filtered_d, region):\n",
    "    \"\"\"\n",
    "    Calculate the count of unique clients based on the provided conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_df (DataFrame): A DataFrame filtered to include only rows where 'TYPE' is 'ROZ'.\n",
    "    - region (str): The specific region for which to calculate the count of unique clients.\n",
    "\n",
    "    Returns:\n",
    "    int: The count of unique clients for the given region.\n",
    "    \"\"\"\n",
    "    return len(filtered_d[(filtered_d['RegionType'] == region) & (filtered_d['TYPE'] == 'ROZ')]['inn'].unique())\n",
    "\n",
    "\n",
    "def calculate_fact_to(region, region_type, *aksiya_value):\n",
    "    \"\"\"\n",
    "    Calculate the 'Факт ТО' for a specific region, product type, and aksiya value.\n",
    "\n",
    "    Parameters:\n",
    "    - region (str): The specific region for which to calculate 'Факт ТО'.\n",
    "    - region_type (str): The specific product type for which to calculate 'Факт ТО'.\n",
    "    - aksiya_value (str, optional): The specific value for 'aksiya' to be considered in the calculation.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated 'Факт ТО'.\n",
    "    \"\"\"\n",
    "    filtered_region_df = filtered_df[(filtered_df['Region'] == region) & (filtered_df['TYPE'] == region_type)]\n",
    "\n",
    "    if aksiya_value:\n",
    "        filtered_region_df = filtered_region_df[filtered_region_df['Aksiya'] == aksiya_value[0]]\n",
    "        return max(filtered_region_df['Kolich'].sum(), 0)\n",
    "\n",
    "    return max(filtered_region_df['TotalAmount'].sum(), 0)\n",
    "\n",
    "\n",
    "def calculate_percentage(fact_column, plan_column):\n",
    "    \"\"\"\n",
    "    Calculate the percentage based on 'Факт' and 'План' columns.\n",
    "\n",
    "    Parameters:\n",
    "    - fact_column (Series): The Series representing the 'Факт' column.\n",
    "    - plan_column (Series): The Series representing the 'План' column.\n",
    "\n",
    "    Returns:\n",
    "    Series: The calculated percentage column.\n",
    "    \"\"\"\n",
    "    return (fact_column / plan_column).fillna(1) * 100\n",
    "\n",
    "\n",
    "# Load data from hourly.xlsx\n",
    "input_file_path = 'Hourly.xlsx'\n",
    "plan_path = 'D:/Projects/plan.xlsx'\n",
    "# Read plan data from plan.xlsx\n",
    "plan_df = pd.read_excel(plan_path, sheet_name=\"ROZ\")\n",
    "df = pd.read_excel(input_file_path)\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'TYPE' is 'ROZ'\n",
    "filtered_df = df[df['TYPE'] == 'ROZ']\n",
    "\n",
    "# Define unique values for TYPE\n",
    "unique_types = filtered_df['TYPE'].unique()\n",
    "\n",
    "# Defined the specific Plan Columns i need\n",
    "region_combinations = plan_df[['Region', 'TO', 'Rinomaks', 'Forsil', 'Тризим Таб', 'Тризим Кап', 'Энтеросгель']]\n",
    "\n",
    "# Calculate 'Факт ТО' and '%' for each product type\n",
    "for product_type in unique_types:\n",
    "    fact_column = f'Fact ТО {product_type}'\n",
    "    percent_column = f'% {product_type}'\n",
    "\n",
    "    region_combinations[fact_column] = region_combinations['Region'].apply(\n",
    "        lambda region: calculate_fact_to(region, product_type))\n",
    "\n",
    "    region_combinations[percent_column] = calculate_percentage(region_combinations[fact_column],\n",
    "                                                               region_combinations['TO'])\n",
    "\n",
    "# Add 'OXVAT' column based on the provided formula\n",
    "region_combinations['OXVAT'] = region_combinations['Region'].apply(lambda region: calculate_oxvat(filtered_df, region))\n",
    "\n",
    "# Add Rinomaks columns\n",
    "region_combinations['Fact Rinomaks'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Рино'))\n",
    "region_combinations['% Rinomaks'] = calculate_percentage(region_combinations['Fact Rinomaks'],\n",
    "                                                         region_combinations['Rinomaks'])\n",
    "# FORSIL\n",
    "region_combinations['Fact FORSIL'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Форсил'))\n",
    "region_combinations['% FORSIL'] = calculate_percentage(region_combinations['Fact FORSIL'],\n",
    "                                                       region_combinations['Forsil'])\n",
    "\n",
    "region_combinations['Fact Тризим Таб'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Тризим №20'))\n",
    "region_combinations['% Тризим Таб'] = calculate_percentage(region_combinations['Fact Тризим Таб'],\n",
    "                                                           region_combinations['Тризим Таб'])\n",
    "\n",
    "region_combinations['Fact Тризим Кап'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Тризим Кап'))\n",
    "region_combinations['% Тризим Кап'] = calculate_percentage(region_combinations['Fact Тризим Кап'],\n",
    "                                                           region_combinations['Тризим Кап'])\n",
    "\n",
    "region_combinations['Fact Энтеросгель'] = region_combinations['Region'].apply(\n",
    "    lambda region: calculate_fact_to(region, 'ROZ', 'Энтеросгель'))\n",
    "region_combinations['% Энтеросгель'] = calculate_percentage(region_combinations['Fact Энтеросгель'],\n",
    "                                                            region_combinations['Энтеросгель'])\n",
    "# COLUMN RENAME TO RUSSIAN LETTERS FROM ENGLISH\n",
    "column_mapping = {\n",
    "    'Region': 'Регион',\n",
    "    'TO': 'TO',\n",
    "    'Fact ТО ROZ': 'Факт ТО',\n",
    "    '% ROZ': '% TO',\n",
    "    'OXVAT': 'Охват',\n",
    "    'Rinomaks': 'Риномакс',\n",
    "    'Fact Rinomaks': 'Факт Риномакс',\n",
    "    '% Rinomaks': '% Риномакс',\n",
    "    'Forsil': 'Форсил',\n",
    "    'Fact FORSIL': 'Факт Форсил',\n",
    "    '% FORSIL': '% Форсил',\n",
    "    'Тризим Таб': 'Тризим Таб',\n",
    "    'Fact Тризим Таб': 'Факт Тризим Таб',\n",
    "    '% Тризим Таб': '% Тризим Таб',\n",
    "    'Тризим Кап': 'Тризим Кап',\n",
    "    'Fact Тризим Кап': 'Факт Тризим Кап',\n",
    "    '% Тризим Кап': '% Тризим Кап',\n",
    "    'Энтеросгель': 'Энтеросгель',\n",
    "    'Fact Энтеросгель': 'Факт Энтеросгель',\n",
    "    '% Энтеросгель': '% Энтеросгель'\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping dictionary\n",
    "region_combinations = region_combinations.rename(columns=column_mapping)\n",
    "# Sorting to look it pretty\n",
    "region_combinations.sort_values(by='% TO', ascending=False, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:43.452247300Z",
     "start_time": "2024-01-24T12:39:42.266176200Z"
    }
   },
   "id": "ae3218d782958698",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_row= pd.Series({\n",
    "    'Регион': 'TOTAL',\n",
    "    'TO': region_combinations['TO'].sum(),\n",
    "    'Факт ТО': region_combinations['Факт ТО'].sum(),\n",
    "    '% TO': (region_combinations['Факт ТО'].sum() / region_combinations['TO'].sum()) * 100,\n",
    "    'Охват': region_combinations['Охват'].sum(),\n",
    "    'Риномакс': region_combinations['Риномакс'].sum(),\n",
    "    'Факт Риномакс': region_combinations['Факт Риномакс'].sum(),\n",
    "    '% Риномакс': (region_combinations['Факт Риномакс'].sum() / region_combinations['Риномакс'].sum()) * 100,\n",
    "    'Форсил': region_combinations['Форсил'].sum(),\n",
    "    'Факт Форсил': region_combinations['Факт Форсил'].sum(),\n",
    "    '% Форсил': (region_combinations['Факт Форсил'].sum() / region_combinations['Форсил'].sum()) * 100,\n",
    "    'Тризим Таб': region_combinations['Тризим Таб'].sum(),\n",
    "    'Факт Тризим Таб': region_combinations['Факт Тризим Таб'].sum(),\n",
    "    '% Тризим Таб': (region_combinations['Факт Тризим Таб'].sum() / region_combinations['Тризим Таб'].sum()) * 100,\n",
    "    'Тризим Кап': region_combinations['Тризим Кап'].sum(),\n",
    "    'Факт Тризим Кап': region_combinations['Факт Тризим Кап'].sum(),\n",
    "    '% Тризим Кап': (region_combinations['Факт Тризим Кап'].sum() / region_combinations['Тризим Кап'].sum()) * 100,\n",
    "    'Энтеросгель': region_combinations['Энтеросгель'].sum(),\n",
    "    'Факт Энтеросгель': region_combinations['Факт Энтеросгель'].sum(),\n",
    "    '% Энтеросгель': (region_combinations['Факт Энтеросгель'].sum() / region_combinations['Энтеросгель'].sum()) * 100\n",
    "}, name='TOTAL')\n",
    "\n",
    "region_combinations = pd.concat([region_combinations, total_row.to_frame().transpose()], ignore_index=True)\n",
    "region_combinations=region_combinations[['Регион', 'TO', 'Факт ТО', '% TO', 'Охват', 'Риномакс', 'Факт Риномакс',\n",
    "                     '% Риномакс', 'Форсил', 'Факт Форсил', '% Форсил', 'Тризим Таб', 'Факт Тризим Таб',\n",
    "                     '% Тризим Таб', 'Тризим Кап', 'Факт Тризим Кап', '% Тризим Кап',\n",
    "                     'Энтеросгель', 'Факт Энтеросгель', '% Энтеросгель']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-24T12:39:43.450028Z"
    }
   },
   "id": "5ce376fbaf4b8b70",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "region_combinations.to_excel('Salom.xlsx',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T12:39:45.019359800Z",
     "start_time": "2024-01-24T12:39:44.955668Z"
    }
   },
   "id": "46da1f2da139e4e8",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f349efa333c35e4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
