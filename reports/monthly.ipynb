{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta  # For working with dates\n",
    "import time\n",
    "import pandas as pd  # For working with DataFrames\n",
    "from dotenv import load_dotenv\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import NamedStyle, PatternFill, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from sqlalchemy import create_engine  # For crea\n",
    "\n",
    "##################### LOADING IMPORTANT DATA ######################\n",
    "# Load environment variables from the .env file\n",
    "env_file_path = r'D:/Projects/.env'\n",
    "load_dotenv(env_file_path)\n",
    "# Giving output file name\n",
    "output_file_path = 'MONTHLY.xlsx'\n",
    "# Load data from different sheets in 'promotion.xlsx' into DataFrames\n",
    "promotion_path = r'D:\\Projects\\promotion.xlsx'\n",
    "region_df = pd.read_excel(promotion_path, sheet_name='Region')\n",
    "aksiya_df = pd.read_excel(promotion_path, sheet_name='Aksiya')\n",
    "paket_df = pd.read_excel(promotion_path, sheet_name='Paket')\n",
    "types_df = pd.read_excel(promotion_path, sheet_name='TYPES')\n",
    "##################### ACCESS ENV VARIABLES ######################\n",
    "db_server = os.getenv(\"DB_SERVER\")\n",
    "db_database = os.getenv(\"DB_DATABASE_ASKGLOBAL\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "db_driver_name = os.getenv(\"DB_DRIVER_NAME\")\n",
    "\n",
    "##################### PROCEDURE NAME ######################\n",
    "procedure_name = os.getenv(\"MONTHLY\")  # THIS IS HOURLY DATA GATHERING\n",
    "\n",
    "start_date = datetime(2024,2,1).strftime('%Y%m%d')\n",
    "tomorrow_date = datetime(2024, 3, 31).strftime('%Y%m%d')\n",
    "##################### CONNECTION STRING AND SQL QUERY ######################\n",
    "# Construct the connection string\n",
    "conn_str = f\"mssql+pyodbc://{db_user}:{db_password}@{db_server}:{db_port}/{db_database}?driver={db_driver_name}\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "sql_query: str = f\"\"\"\n",
    "DECLARE @DateBegin DATE = ?;\n",
    "DECLARE @DateEnd DATE = ?;\n",
    "\n",
    "EXEC {procedure_name}\n",
    "@DataBegin = @DateBegin,\n",
    "@DataEnd = @DateEnd;\n",
    "\"\"\"\n",
    "\n",
    "#####################  EXECUTION  ######################\n",
    "df = pd.read_sql_query(sql_query, engine, params=(start_date, tomorrow_date))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "281ccbaff982c5c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "df = df[df['DocName'].isin(['Оптовая реализация', 'Финансовая скидка', 'Возврат товара от покупателя'])]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3806f46a2e733bd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.drop(columns='Postavshik', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8744b89ce4b2c54",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df[(df['DataEntered'].dt.year == 2024) & (df['DataEntered'].dt.month==2)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32deb12852a8ee9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.merge(df, region_df[['ClientMan', 'Region']], left_on='ClientManager', right_on='ClientMan', how='left')\n",
    "\n",
    "df = pd.merge(df, aksiya_df[['Goodid', 'Aksiya']], left_on='Goodid', right_on='Goodid', how='left')\n",
    "df = pd.merge(df, paket_df[['Goodid', 'Paket']], left_on='Goodid', right_on='Goodid', how='left')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7d114637dc6f31",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dfx=df.INN.unique()\n",
    "dfx"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fb5162b64b19889",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "url = \"https://orginfo.uz/en/search/organizations/\"\n",
    "# inns = [inn for inn in df.INN.unique()[:30]]\n",
    "\n",
    "def process_inn(inn):\n",
    "    params = {'q': inn}\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        results = soup.find_all('a', class_='og-card')\n",
    "\n",
    "        for result in results:\n",
    "            organization_link = result['href']\n",
    "            organization_url = f\"https://orginfo.uz{organization_link}\"\n",
    "\n",
    "            organization_response = requests.get(organization_url)\n",
    "\n",
    "            if organization_response.status_code == 200:\n",
    "                organization_soup = BeautifulSoup(organization_response.text, 'html.parser')\n",
    "                organization_name = organization_soup.select_one('.h1-seo').text.strip()\n",
    "                details_rows = organization_soup.select('.row.border-bottom.py-3')\n",
    "\n",
    "                with open(\"output.txt\", \"a\", encoding=\"utf-8\") as output_file:\n",
    "                    output_file.write(f\"Organization Name: {organization_name}\\n\")\n",
    "                    output_file.write(\"Details:\\n\")\n",
    "\n",
    "                    for row in details_rows:\n",
    "                        span_elements = row.find_all('span')\n",
    "\n",
    "                        if len(span_elements) >= 2:\n",
    "                            key = span_elements[0].text.strip()\n",
    "                            value = span_elements[1].text.strip()\n",
    "                            output_file.write(f\"{key} | {value}\\n\")\n",
    "\n",
    "                    output_file.write(\"\\n====================\\n\")\n",
    "\n",
    "            else:\n",
    "                with open(\"output.txt\", \"a\", encoding=\"utf-8\") as output_file:\n",
    "                    output_file.write(f\"Failed to retrieve information for organization at {organization_url}. Status Code: {organization_response.status_code}\\n\")\n",
    "\n",
    "    else:\n",
    "        with open(\"output.txt\", \"a\", encoding=\"utf-8\") as output_file:\n",
    "            output_file.write(f\"Failed to retrieve information for INN {inn}. Status Code: {response.status_code}\\n\")\n",
    "\n",
    "# Use ThreadPoolExecutor to run multiple threads concurrently\n",
    "# with ThreadPoolExecutor() as executor:\n",
    "#     executor.map(process_inn, inns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f45445e3ea58b0f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Assuming `dfx` is pandas DataFrame containing 'INN' values\n",
    "inn_list = [inn for inn in dfx]\n",
    "\n",
    "# Set the URLs for the main page and the result page\n",
    "url = \"https://registr.stat.uz/ru/\"\n",
    "result_url = \"https://registr.stat.uz/ru/result/\"\n",
    "\n",
    "# Set up Chrome options for headless mode\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')  # Run Chrome in headless mode (without GUI)\n",
    "chrome_options.add_argument('--disable-gpu')  # Disable GPU acceleration for headless mode\n",
    "chrome_options.add_argument('--window-size=1920x1080')  # Set the window size for headless mode\n",
    "\n",
    "# Create an empty list to store results\n",
    "result_data = []\n",
    "\n",
    "# Function to process a single inn value\n",
    "def process_inn(inn):\n",
    "    result_dict = {'INN': inn}\n",
    "\n",
    "    try:\n",
    "        # Set up the browser with headless mode\n",
    "        driver = webdriver.Chrome(options=chrome_options)  # You need to have chromedriver installed\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        # Fill the form on the main page\n",
    "        inn_input = driver.find_element(By.NAME, \"OKPO\") # it is written in the site as OKPO\n",
    "        inn_input.send_keys(inn)\n",
    "\n",
    "        checkbox = driver.find_element(By.XPATH, \"//input[@type='checkbox']\")\n",
    "        checkbox.click()\n",
    "\n",
    "        # Submit the form\n",
    "        submit_button = driver.find_element(By.NAME, \"submit\")\n",
    "        submit_button.click()\n",
    "\n",
    "        # Wait for the result page to load\n",
    "        WebDriverWait(driver, 10).until(EC.url_to_be(result_url))\n",
    "\n",
    "        # Get the content of the result page\n",
    "        result_page_content = driver.page_source\n",
    "\n",
    "        # Process the result page content using BeautifulSoup\n",
    "        soup = BeautifulSoup(result_page_content, 'html.parser')\n",
    "        result_div = soup.find('div', {'id': 'demo2'})\n",
    "        if result_div:\n",
    "            result_text = result_div.text\n",
    "\n",
    "            # Split the text into lines\n",
    "            lines = result_text.split('\\n')\n",
    "\n",
    "            # Create a dictionary to store the extracted information\n",
    "            for line in lines:\n",
    "                # Split each line into parts based on ':'\n",
    "                parts = line.split(':')\n",
    "                if len(parts) == 2:\n",
    "                    key = parts[0].strip()\n",
    "                    value = parts[1].strip()\n",
    "                    result_dict[key] = value\n",
    "        else:\n",
    "            result_dict['Result'] = 'Result div not found on the page'\n",
    "\n",
    "    except Exception as e:\n",
    "        result_dict['Result'] = f\"Error processing INN {inn}: {str(e)}\"\n",
    "\n",
    "    finally:\n",
    "        driver.quit()  # Close the browser window\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Use ThreadPoolExecutor to run multiple threads concurrently\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    result_data = list(executor.map(process_inn, inn_list))\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "result_df = pd.DataFrame(result_data)\n",
    "\n",
    "# Export the DataFrame to Excel\n",
    "result_df.to_excel('result_output.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a2996b6361ee31",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
